# 分析機能仕様

## 行動経済学分析

### リスク選好度分析

#### 高額物件投資率

- 総資産に対する高額物件（購入価格 > $300）への投資比率
- 投資タイミングと資産状況の相関分析

#### 現金保有率

- ターンごとの現金/総資産比率
- 安全志向 vs 攻撃的投資の判定

#### 可視化

- レーダーチャートで複数指標を表示

### 損失回避バイアス

#### 緊急時の抵当率

- 支払い困難時の抵当設定パターン
- 損失確定（物件売却）を避ける傾向の測定

#### 破産リスク分析

- 現金不足に陥った回数
- リスク状況下での意思決定パターン

### サンクコスト効果

#### 継続投資パターン

- 同一物件グループへの追加投資判断
- 投資回収見込みと投資継続の相関
- 不利な物件への固執傾向

### オークション行動

#### 過剰入札検出

- 物件価格に対する入札額の比率
- 市場価格（定価）を超える入札の頻度

#### 競争心理

- 競合プレイヤー数と入札額の相関
- 競り合いでの撤退/継続判断

## ゲーム理論分析

### ナッシュ均衡分析

#### 最適戦略との乖離度

- 理論上の最適行動と実際の行動の差異
- 状況別の戦略選択の一貫性

#### 戦略一貫性評価

- 同様の状況での行動の再現性
- 学習効果の測定

### 協力 vs 競争

#### 取引パターン分析

- 取引頻度、取引相手の分布
- Win-Win取引 vs ゼロサムゲーム的取引

#### 競争的行動

- オークションでの競合行動
- 特定プレイヤーへの敵対的行動の検出

### 支配戦略

#### 戦略パターンの特定

- 頻繁に使用される行動パターン
- 状況別の支配的な選択

#### 戦略の成功率

- 各戦略と最終順位の相関
- 有効戦略の抽出

### パレート効率性

#### 市場効率性

- 取引による総資産の変化
- 資源配分の最適性評価

#### 取引の効率性

- 取引後の両者の資産推移
- 非効率な取引の検出

## 時系列分析

### 総資産の推移

- **データ**: ターンごとの各プレイヤーの総資産
- **計算**: 現金 + 物件価値 + 建物価値 - 抵当額
- **可視化**: ラインチャート
- **分析観点**:
  - 資産増減の傾向
  - ターニングポイントの特定
  - プレイヤー間の格差拡大/縮小

### 現金保有の推移

- **データ**: ターンごとの現金残高
- **可視化**: ラインチャート
- **分析観点**:
  - 流動性管理の巧拙
  - 現金枯渇リスクの推移
  - 投資タイミングとの相関

### 物件保有数の推移

- **データ**: ターンごとの所有物件数
- **可視化**: ラインチャート
- **分析観点**:
  - 物件獲得ペース
  - モノポリー形成の速度
  - 拡大戦略 vs 集中戦略

### マーケットシェア

- **データ**: 各プレイヤーの総資産比率
- **可視化**: 積み上げグラフ（100%スタック）
- **分析観点**:
  - 勢力図の変化
  - 支配的プレイヤーの特定
  - 逆転のタイミング

### 勢力変化

- **データ**: ターンごとの順位変動
- **検出項目**:
  - 順位変動の頻度
  - 急激な資産変化のターン
  - 重要イベント（大型取引、破産等）
- **可視化**: 順位推移グラフ

## 強化学習用データ

### State-Action-Reward形式

#### State（状態）

- プレイヤーの現金、位置、所有物件
- 他プレイヤーの資産状況
- ボードの状態（物件所有者、建物数）
- ターン数、ゲーム進行状況

#### Action（行動）

- 物件購入/拒否
- オークション入札額
- 建物建設
- 取引提案/応答
- 抵当設定/解除

#### Reward（報酬）

- 即時報酬: 現金増減、資産変化
- 遅延報酬: 最終順位に基づくスコア
- 中間報酬: 総資産順位の変動

### OpenAI Gym形式エクスポート

#### 標準インターフェース

```python
env.reset() -> observation
env.step(action) -> observation, reward, done, info
```

#### 構成要素

- **観測空間**: 状態ベクトルの定義
- **行動空間**: 離散行動または連続行動
- **報酬関数**: カスタマイズ可能
- **エピソード終了条件**: ゲーム終了時

### TensorFlow形式エクスポート

#### データ構造

- 正規化済み状態ベクトル
- one-hot エンコード済み行動
- スケール済み報酬

#### フォーマット

- TFRecord形式
- NumPy配列
- CSV形式

#### メタデータ

- 特徴量の次元
- 正規化パラメータ
- 行動空間の定義

### ポリシー分析

#### プレイヤー別行動分布

- 状況別の行動選択確率
- 戦略パターンの可視化
- 決定論的 vs 確率的行動

#### 報酬分析

- 行動ごとの期待報酬
- 累積報酬の推移
- 最適行動との比較

### 時系列報酬

- **データ**: ターンごとの報酬推移
- **可視化**: 学習曲線
- **分析項目**:
  - 報酬の収束性
  - 探索 vs 活用のバランス
  - エピソード間の学習進捗
